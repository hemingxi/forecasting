---
title: "fpp-ch-10"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

# Load Packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table) 
library(fpp3)
library(readr)
library(USgas)
library(scales)
library(readxl)
library(ggdist)
library(urca)
library(purrr)

```

# Qn 1

```{r}
typeof(LakeHuron)

lake <- LakeHuron |>  
  as_tsibble()

lake |> index()

lake |> autoplot(value)

lake_mod <- lake |> 
  model(
    tslm_piecewise = TSLM(value ~ trend(knots = c(1920))),
    arima = ARIMA(value ~ trend(knots = c(1920)))
  )

lake_mod

lake_mod |> glance()

lake_mod |> 
  select(arima) |> 
  report()
  

lake_mod |> 
  select(arima) |> 
  fitted() |> 
  autoplot(.fitted, color = "blue") +
  autolayer(lake, value)

fc_lake <- lake_mod |> 
  forecast(h = "30 years")

fc_lake |> 
  filter(.model == "arima") |> 
  autoplot(lake)

```

Does the extrapolated linear trend look realistic? I don't think so, there's no reason to assume that there is an upward trend from 1920 onwards. The year to year variation is much larger

Let's look at the residuals.

```{r}
tslm <- lake_mod |> 
  select(tslm_piecewise) 

tslm |> 
  gg_tsresiduals()

tslm |> 
  augment() |> 
  gg_tsdisplay(.resid, plot_type = "partial")

```


# Qn 2

```{r}
souvenirs |> autoplot(Sales)

souv <- souvenirs |> 
  mutate(surffest = month(Month) == 3 & Month >= yearmonth("1988 Mar"))

# https://stackoverflow.com/questions/6558921/boolean-operators-and
# & is vectorized, meaning it will return a vector of trues and falses
# && is not vectorized and will go left to right and examine one by one and short circuit
# & should be used when creating vectors
# && should be used for programming control-flow and is preferred in if clauses
# You should be absolutely certain your vectors are only length 1, such as in cases where they are functions that return only length 1 booleans. You want to use the short forms if the vectors are length possibly >1. So if you're not absolutely sure, you should either check first, or use the short form and then use all and any to reduce it to length one for use in control flow statements, like if

souv

```

Let's do the model now.

```{r}
souv_mod <- souv |> 
  model(
    tslm = TSLM(log(Sales) ~ surffest + trend() + season()) ,
    arima = ARIMA(log(Sales) ~ surffest + trend() + season())
  )

souv_tslm <- souv_mod |> select(tslm) 
souv_tslm |> report()

souv_arima <- souv_mod |> select(arima) 
souv_arima |> report()

```

There is a bit of a difference to the regression coefficients. The trend is still the same, but the regression coefficients can now more properly pick up the signal, instead of trying to fit the ARIMA error - i.e. if the previous month was high, then the next month will also likely be high.

```{r}

souv_new <- new_data(souv, n = 1*12) |> 
  mutate(surffest = (month(Month)==3) & (Month >= yearmonth("1988 Mar")))

souv_new

fc_souv <- souv_mod |> 
  forecast(new_data = souv_new) # you don't have to specify the forecast length if you give it new data 

fc_souv

fc_souv |> autoplot(souv)

fc_souv |> filter(.model == "tslm") |> autoplot(souv)
fc_souv |> filter(.model == "arima") |> autoplot(souv)

```

There doesn't seem to be a significant difference in the forecasts.

I want to try and plot the lower and upper bound in the same plot:

```{r}
fc_souv <- fc_souv |> 
  hilo() |> 
  mutate(
    lower = `95%`$lower,
    upper = `95%`$upper
  )

fc_souv |> head()

fc_souv |> ggplot(aes(x = Month)) +
  geom_line(aes(y = .mean), color = "blue") +
  facet_grid(.model ~ .) +
  geom_line(aes(y = upper), color = "blue", alpha = .25) +
  geom_line(aes(y = lower), color = "blue", alpha = .25) +
  geom_line(data = souv, aes(x = Month, y = Sales)) +
  scale_y_log10()
 
#unpack_hilo does not work with the recent update (to dplyr I think)
  unpack_hilo(`95%`)

# https://stackoverflow.com/questions/74437685/unnest-dist-column-from-fabletoolsforecast-output
#trying to figure out how to unpack the distribution object
# fc_souv[["Sales"]][[1]]
# 
# typeof(fc_souv$"Sales")
# 
# class(fc_souv$Sales)
# fc_souv |> summarise_all(class)

```


Check Residuals

```{r}
souv_tslm |> gg_tsresiduals()

souv_arima |> gg_tsresiduals()
```


# Qn 3

```{r}
vic_elec_daily <- vic_elec |>
  filter(year(Time) == 2014) |>
  index_by(Date = date(Time)) |>
  summarise(
    Demand = sum(Demand)/1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)) |>
  mutate(
    Temp2 = I(pmax(Temperature-25,0)),
    Day_Type = case_when(
      Holiday ~ "Holiday",
      wday(Date) %in% 2:6 ~ "Weekday",
      TRUE ~ "Weekend"))

head(vic_elec_daily)

```

```{r}
vic_elec_daily |> autoplot(Demand)
```

```{r}
vic_elec_daily |> 
  ggplot(aes(x = Temperature, y = Demand, color = Day_Type)) +
  geom_point()
```

```{r}
elec_model <- vic_elec_daily |> 
  model(ARIMA(Demand ~ Temperature + Temp2 + (Day_Type == "Weekday")))

elec_model |> gg_tsresiduals()

```
We can optimize the choice of by first doing a hand selection based on the Temp*Demand graph. Then, we can try a few different knots and see which one performs the best on the testing.

#Qn 4

```{r}
head(aus_accommodation)

aus_accommodation |> 
  distinct(State)

aus_accommodation |> autoplot(CPI)

CPI_1 <- aus_accommodation |> 
  pull(CPI) |> 
  min()

#instead of dividing by the 1st CPI, we will divide by 100 to ake it easier

aus <- aus_accommodation |> 
  mutate(
    CPI_index = CPI / 100,
    #`Takings/CPI_index` = Takings / CPI_index,
    Takings_CPI = Takings / CPI_index
  )

aus |> 
  filter(State == "New South Wales") |> 
  ggplot(aes(x = Date)) +
  geom_line(aes(y = Takings)) + 
  geom_line(aes(y = Takings_CPI), color = "blue")

index(aus)
key(aus)

```


```{r}
mod <- aus |> model(
  arima_model = ARIMA(Takings_CPI ~ trend(knots = yearquarter(c("2008 Q1"))) + season()) 
)

mod
mod |> glance() # why is no information showing up for the glance?
mod |> tidy()
mod |> filter(State == "New South Wales") |> report()

mod |> forecast(h=5) |> 
  autoplot()

```

## 4c

Check residuals.

```{r}

for(i in 1:nrow(mod)) {
  print(i)
  mod[i,] |>  
    gg_tsresiduals() |> 
    print()
}

```

I am trying to functionally loop over and print the graphs. 


```{r}

print_info  <- function(obj, in_key){
  obj |> as_mable(key = State, model = arima_model) |> gg_tsresiduals() |>  print()
}

mod |> group_by(row_number()) |>  group_walk(print_info)

```

## 4d

Check range of original data

```{r}

(max_dt <- aus_accommodation |> 
  pull(Date) |> 
  max())

(min_dt <- aus_accommodation |> 
    pull(Date) |> 
    min())

#so we need to forecast 6 quarters forward

fc_h = yearquarter("2017 Q4") - max_dt

```

Redo the model

```{r}
aus <- aus_accommodation |> 
  mutate(
    CPI_index = CPI / 100,
    Takings_CPI = Takings / CPI_index
  )


mod <- aus |> model(
  arima_model = ARIMA(Takings_CPI ~ trend(knots = yearquarter(c("2008 Q1"))) + season()) 
)

```


Forecast CPI

```{r}

aus_accommodation |> autoplot(CPI) +
  scale_y_log10()

# this causes issues with autoplot later
# CPI_mod <- aus_accommodation |> 
#   summarize(avg_CPI = mean(CPI)) |> 
#   model(
#     cpi_arima = ARIMA(log(avg_CPI) ~ trend() + season())
#   )

CPI_mod <- aus_accommodation |>
  model(
    cpi_arima = ARIMA(log(CPI) ~ trend() + season())
  )

CPI_mod |> 
  filter(State == "New South Wales") |> 
  report()

CPI_fc <- CPI_mod |> 
  forecast(h=fc_h)

CPI_fc |>
  filter(State == "New South Wales") |>  
  autoplot(aus_accommodation)

#CPI_fc |> pull(Date) |> max()


(new_aus <- new_data(aus_accommodation, n = fc_h) |> 
    left_join(CPI_fc) |> 
    transmute(
      Date = Date,
      State = State,
      CPI_index = .mean/100
    ))

mod

fc_aus <- mod |> 
  forecast(new_data = new_aus) # you can't have the extra variables in new_data

fc_aus

fc_aus |> autoplot(aus) + facet_wrap(vars(State), scales = "free_y")

```

How do we plot the forecasts on the original scale? 
I've generated some code below that does that, I'm not sure if autoplot will do it?

To answer the question, the confidence intervals are calculated conditional on the other variables in the regression. For example, CPI is an explanatory variable in our regression. In order to forecast Takings, we needed some forecasts for CPI. These forecasts could be wrong, making our forecasts for Takings wrong.


```{r}

fc <- fc_aus |> 
  mutate(
    Takings = Takings_CPI*CPI_index,
    Takings_hilo = hilo(Takings, level = 95)
  ) 

fc |> class()

aus_accommodation

fc |> 
  ggplot(aes(x = Date)) +
  geom_lineribbon(aes(ymin = Takings_hilo$lower, ymax = Takings_hilo$upper),  fill = "blue", alpha = .25) + 
  geom_line(aes(y = .mean*CPI_index), color = "blue") +
  facet_wrap(vars(State), scales = "free_y") +
  geom_line(data = aus_accommodation, aes(x = Date, y = Takings))
  

```


For the previous question, try doing a log transform and adding log(CPI) to the regression

```{r}
aus_accommodation

aus_accommodation |> autoplot(Takings)

aus_accommodation |> autoplot(Takings) + scale_y_log10()


aus <- aus_accommodation |> 
  mutate(
    CPI_index = CPI / 100,
    #`Takings/CPI_index` = Takings / CPI_index,
    Takings_CPI = Takings / CPI_index
  )

aus_mod <- aus |> 
  model(
    arima_model = ARIMA(Takings_CPI ~ trend(knots = yearquarter(c("2008 Q1"))) + season()) 
  )

aus_mod_log <- aus |> 
  model(
    log_arima = ARIMA(log(Takings) ~ log(CPI_index) + trend(knots = yearquarter(c("2008 Q1"))) + season())
  )
    

```

Print the residuals graphs:

```{r}
print_info  <- function(obj, in_key){
  obj |> as_mable(key = State, model = arima_model) |> gg_tsresiduals() |>  print()
}

aus_mod |> group_by(row_number()) |>  group_walk(print_info)

```


```{r}

print_info  <- function(obj, in_key){
  obj |> as_mable(key = State, model = log_arima) |> gg_tsresiduals() |>  print()
}

aus_mod_log |> group_by(row_number()) |>  group_walk(print_info)
```

And you can model from here. The log model seems a bit better, and you can adjust for CPI directly in the model call, meaning that instead of creating our own custom code, we can use the standard tools.


# Qn 5 Harmonic Regression

We fitted a harmonic regression model to part of the us_gasoline series in Exercise 5 in Section 7.10. We will now revisit this model, and extend it to include more data and ARMA errors.

## 5a

Using TSLM(), fit a harmonic regression with a piecewise linear time trend to the full series. Select the position of the knots in the trend and the appropriate number of Fourier terms to include by minimising the AICc or CV value.


```{r}
us_gasoline |> head()


us_gasoline |> autoplot(Barrels)

#model code:
fourier_beer <- recent_production |>
  model(TSLM(Beer ~ trend() + fourier(K = 2)))
report(fourier_beer)


```




# Follow up Questions

What does the trend or season functions actually do?

How do the transformations work within a model call? Are we back-transforming the confidence intervals into the original scale, or is there something more that is being done there?

This is some reference code that can be deleted:








